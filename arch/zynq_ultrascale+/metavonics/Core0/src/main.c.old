#include <stdio.h>
#include <stdlib.h>
#include "platform.h"
#include "xil_printf.h"
#include "xil_cache.h"
#include "PMU.h"
#include "xtime_l.h"
#include "xil_mmu.h"
#include <time.h>
#include <errno.h>
#include <assert.h>
#include <math.h>

#include <unistd.h>

int msleep(unsigned int tms) {
	return usleep(tms * 1000);
}

static XTime XMt_CalcTime(XTime tCur) {
	XTime tEnd;
	XTime tDiff;
	XTime_GetTime(&tEnd);
	tDiff = tEnd - tCur;
	return tDiff;
}

static void enable_cycle_counter_el0(void) {
	uint64_t val;
	/* Disable cycle counter overflow interrupt */
	asm volatile("msr pmintenset_el1, %0" : : "r" ((uint64_t)(0 << 31)));
	/* Enable cycle counter */
	asm volatile("msr pmcntenset_el0, %0" :: "r" (1 << 31));
	/* Enable user-mode access to cycle counters. */
	asm volatile("msr pmuserenr_el0, %0" :: "r" ((1 << 0) | (1 << 2)));
	/* Clear cycle counter and start */
	asm volatile("mrs %0, pmcr_el0" : "=r" (val));
	val |= ((1 << 0) | (1 << 2));
	asm volatile("isb");
	asm volatile("msr pmcr_el0, %0" :: "r" (val));
	val = (1 << 27);
	asm volatile("msr pmccfiltr_el0, %0" :: "r" (val));
}

static inline uint64_t read_pmccntr(void) {
	uint64_t val;
	asm volatile("mrs %0, pmccntr_el0" : "=r"(val));
	return val;
}


#define L1CacheFillLoad

#if defined(L1CacheFillLoad)
/*
 * MACRO USAGE:
 * ARGUMENTS: POWER OF SETS, POWER OF OFFSET, NUM WAYS, NUM SETS, NUM_BYTES, PTR TO ARRAY
 */
#if defined(EXTENDED)
#define ITER 50
#define PAYLOAD_LOAD(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < 512; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                  \
                "                       \t\
                and x0, %2, 0x3         \t\n\
                lsl x0, x0, %0          \n\t\
                add x1, %3, x0          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                ldrb w0, [%5]           \
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)\
            :"x0", "x1"); \
            }			\
        }			\
    }
#else
#define ITER 5000
#define PAYLOAD_LOAD(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
        for (register u32 way = 0; way < WAYS; way++) {  \
            for (register u32 set = 0; set < SETS; set++) {   \
                for (register u32 byte = 0; byte < OFFSET; byte++) { \
                 __asm__ (                      \
                    "                       \t\
                    lsl x0, %2, %0          \n\t\
                    add x1, %3, %2          \n\t\
                    lsl x1, %3, %1          \n\t\
                    add %5, %3, %4          \n\t\
                    ldrb w0, [%5]           \
                    "                       \
                :                           \
                :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
                :"x0", "x1"); \
				}			\
			}			\
		}
#endif

__attribute__((section(".ddr"))) __attribute__((aligned(1024*32))) volatile u8 target[4][128][64];

int main(s32 argc, char8 **argv) {
    Xil_ConfigureL1Prefetch(0x0U);
    no_allocate_threshold_L1(0b11);
    no_allocate_threshold_L2(0b11);
    Xil_ICacheDisable();
    Xil_DCacheDisable();

    enable_cycle_counter();
    
    for (register u32 ctr = 0; ctr < ITER; ctr++) {
        reset_cycle_counter(0);       
        PAYLOAD_LOAD(7, 6, 4, 128, 64, target);
        printf("%lu\n", (long unsigned) read_cycle_counter());
    }

    return 0;
}
#elif defined(L1CacheFillStore)

/*
 * MACRO USAGE:
 * ARGUMENTS: POWER OF SETS, POWER OF OFFSET, NUM WAYS, NUM SETS, NUM_BYTES, PTR TO ARRAY
 */
#if defined(EXTENDED)
#define ITER 50
#define PAYLOAD_STORE(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < 512; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                      \
                "                       \t\
                and x0, %2, 0x3         \t\n\
                lsl x0, x0, %0          \n\t\
                add x1, %3, x0          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                strb w0, [%5]           \
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
            :"x0", "x1"); \
            }			\
        }			\
    }
#else
#define ITER 5000
#define PAYLOAD_STORE(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
        for (register u32 way = 0; way < WAYS; way++) {  \
            for (register u32 set = 0; set < SETS; set++) {   \
                for (register u32 byte = 0; byte < OFFSET; byte++) { \
                 __asm__ (                      \
                    "                       \t\
                    lsl x0, %2, %0          \n\t\
                    add x1, %3, %2          \n\t\
                    lsl x1, %3, %1          \n\t\
                    add %5, %3, %4          \n\t\
                    strb w0, [%5]           \
                    "                       \
                :                           \ 
                :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
                :"x0", "x1"); \
				}			\
			}			\
		}
#endif

__attribute__((section(".ddr"))) __attribute__((aligned(1024*32))) volatile u8 target[4][128][64];

int main(s32 argc, char8 **argv) {
    Xil_ConfigureL1Prefetch(0x0U);
    no_allocate_threshold_L1(0b11);
    no_allocate_threshold_L2(0b11);
    Xil_ICacheDisable();
    Xil_DCacheDisable();

    enable_cycle_counter();
    
    for (register u32 ctr = 0; ctr < ITER; ctr++) {
        reset_cycle_counter(0);       
        PAYLOAD_STORE(7, 6, 4, 128, 64, target);
        printf("%lu\n", read_cycle_counter());
    }

    return 0;
}

#elif defined(PageFillLoad)

#if defined(BARRIER)
/*
 * MACRO USAGE:
 * ARGUMENTS: POWER OF SETS, POWER OF OFFSET, NUM WAYS, NUM SETS, NUM_BYTES, PTR TO ARRAY
 */
#define PAYLOAD_LOAD(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                      \
                "                       \t\
                lsl x0, %2, %0          \n\t\
                add x1, %3, %2          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                ldrb w0, [%5]           \n\t\
                dsb sy                  \
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
            :"x0", "x1"); \
            }			\
        }			\
    }
#elif defined(ADAPTED)
/*
* Choose this definition if you want to benchmark against the L1D Fill
* Since there is one more instruction in the previous, it is important to
* add the same instruction in the beginning of the bench snippet to have a
* fair comparison
*/
#define PAYLOAD_LOAD(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                      \
                "                       \t\
                and x0, x1, 0x3         \n\t\
                lsl x0, %2, %0          \n\t\
                add x1, %3, %2          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                ldrb w0, [%5]           \n\t\
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
            :"x0", "x1"); \
            }			\
        }			\
    }
#else
#define PAYLOAD_LOAD(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                      \
                "                       \t\
                lsl x0, %2, %0          \n\t\
                add x1, %3, %2          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                ldrb w0, [%5]           \
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
            :"x0", "x1"); \
            }			\
        }			\
    }
#endif

#define ITER 50
#define WAYS 512
#define SETS 128
#define BYTES 64

// 4MB Array
__attribute__((section(".ddr"))) __attribute__((aligned(1024*32))) volatile u8 target[WAYS][SETS][BYTES];

int main(s32 argc, char8 **argv) {
    Xil_ConfigureL1Prefetch(0x0U);
    no_allocate_threshold_L1(0b11);
    no_allocate_threshold_L2(0b11);
    Xil_ICacheDisable();
    Xil_DCacheDisable();

    enable_cycle_counter();
    
    for (register u32 ctr = 0; ctr < ITER; ctr++) {
        reset_cycle_counter(0);       
        PAYLOAD_LOAD(7, 6, WAYS, SETS, BYTES, target);
        printf("%lu\n", read_cycle_counter());
    }

    return 0;
}

#elif defined(PageFillStore)

#if defined(BARRIER)
/*
 * MACRO USAGE:
 * ARGUMENTS: POWER OF SETS, POWER OF OFFSET, NUM WAYS, NUM SETS, NUM_BYTES, PTR TO ARRAY
 */
#define PAYLOAD_STORE(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) { \
        for (register u32 set = 0; set < SETS; set++) {  \
            for (register u32 byte = 0; byte < OFFSET; byte++) {\
                 __asm__ (                      \
                    "                       \t\
                    lsl x0, %2, %0          \n\t\
                    add x1, %3, %2          \n\t\
                    lsl x1, %3, %1          \n\t\
                    add %5, %3, %4          \n\t\
                    strb w0, [%5]           \n\t\
                    dsb sy                  \
                    "                       \
                :                           \ 
                :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
                :"x0", "x1"); \
            }           \
        }           \
    }           
#elif defined(ADAPTED)
/*
* Choose this definition if you want to benchmark against the L1D Fill
* Since there is one more instruction in the previous, it is important to
* add the same instruction in the beginning of the bench snippet to have a
* fair comparison
*/
#define PAYLOAD_STORE(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) {  \
        for (register u32 set = 0; set < SETS; set++) {   \
            for (register u32 byte = 0; byte < OFFSET; byte++) { \
             __asm__ (                      \
                "                       \t\
                and x0, x1, 0x3         \n\t\
                lsl x0, %2, %0          \n\t\
                add x1, %3, %2          \n\t\
                lsl x1, %3, %1          \n\t\
                add %5, %3, %4          \n\t\
                strb w0, [%5]           \n\t\
                "                       \
            :                           \ 
            :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
            :"x0", "x1"); \
            }			\
        }			\
    }
#else
#define PAYLOAD_STORE(PSETS, POFFSET, WAYS, SETS, OFFSET, PTR) \
    for (register u32 way = 0; way < WAYS; way++) { \
        for (register u32 set = 0; set < SETS; set++) {  \
            for (register u32 byte = 0; byte < OFFSET; byte++) {\
                 __asm__ (                      \
                    "                       \t\
                    lsl x0, %2, %0          \n\t\
                    add x1, %3, %2          \n\t\
                    lsl x1, %3, %1          \n\t\
                    add %5, %3, %4          \n\t\
                    strb w0, [%5]           \
                    "                       \
                :                           \ 
                :"i"(PSETS), "i"(POFFSET), "r"(way), "r"(set), "r"(byte), "r"(PTR)  \
                :"x0", "x1"); \
            }           \
        }           \
    }           
#endif

#define ITER 50
#define WAYS 512
#define SETS 128
#define BYTES 64

// 4MB Array
__attribute__((section(".ddr"))) __attribute__((aligned(1024*32))) volatile u8 target[WAYS][SETS][BYTES];

int main(s32 argc, char8 **argv) {
    Xil_ConfigureL1Prefetch(0x0U);
    no_allocate_threshold_L1(0b11);
    no_allocate_threshold_L2(0b11);
    Xil_ICacheDisable();
    Xil_DCacheDisable();

    enable_cycle_counter();
    
    for (register u32 ctr = 0; ctr < ITER; ctr++) {
        reset_cycle_counter(0);       
        PAYLOAD_STORE(7, 6, WAYS, SETS, BYTES, target);
        printf("%lu\n", read_cycle_counter());
    }
    printf("Fin\n");

    return 0;
}
/*
 * This option creates an application that does not use any kind of memory manipulation
 */
#elif defined(independent)

#define MINIBENCH_STORE(REPS, VA, VB) \
    register u32 a = VA;    \
    register u32 b = VB;    \
    for (register u32 c = 0; c < REPS; c++) \
        a ^= (volatile u32) b

int main(s32 argc, char8 **argv) {
    MINIBENCH_STORE(10000, 0, 0);

    return 0;
}

#endif
